---
title: "Data analytic approach to predict heart attack"
author: "Jize(Jesse) Chen"
date: "`r Sys.Date()`"
output: html_document
---

```{r}
#load packages 
library(cli)
library(tidyverse)
library(pls)
library(leaps)
library(readr)
library(dplyr)
library(glmnet)

#import from excel file
BANA_Comp_Data <- read_csv("BANA-Comp-Data.csv")

#attach data set 
attach(BANA_Comp_Data)


#Data cleaning

#completeness 
#count number of missing values in salary
sum(is.na(BANA_Comp_Data)) 
#no value is missing 


#validity
#check data type
glimpse(BANA_Comp_Data)


#change data type of categorical variable from dbl to fct for further analysis 
#sex
BANA_Comp_Data$sex = as.factor(sex) 
#required confirmation with stakeholders. 
#At the moment, assume 0 represents male and 1 represent female 

#cp
BANA_Comp_Data$cp = as.factor(cp)

#fbs
BANA_Comp_Data$fbs = as.factor(fbs)

#restecg
BANA_Comp_Data$restecg = as.factor(restecg)

#exng
BANA_Comp_Data$exng = as.factor(exng)

#slp
BANA_Comp_Data$slp = as.factor(slp)

#thall
BANA_Comp_Data$thall = as.factor(thall)

#output
BANA_Comp_Data$output = as.factor(output)


#accuracy 
#check all possible observation in each variables
#age
unique(age)

#sex
unique(sex)

#cp
unique(cp)

#trtbps
unique(trtbps)

#chol
unique(chol)

#fbs
unique(fbs)

#restecg
unique(restecg)
#remove observations which restecg equals to 2 since 
#there are too few observations restecg eqauls to 2 to 
#produce valuable result 
BANA_Comp_Data.cleaned = BANA_Comp_Data[restecg != '2',]
#check 
unique(BANA_Comp_Data.cleaned$restecg) #restecg == 2 is removed 

#thalachh
unique(thalachh)

#exng
unique(exng)

#oldpeak 
unique(oldpeak)

#slp
unique(slp)

#caa
unique(BANA_Comp_Data$caa) #caa == 4 does not make sense 
#based on data dictionary provided by stakeholder 

#remove observations which caa equals to 4
BANA_Comp_Data.cleaned = BANA_Comp_Data[caa != '4',]
#check 
unique(BANA_Comp_Data.cleaned$caa) #caa == 4 is removed 

#thall
unique(thall)

#remove observations which thall equals to 0 since 
#there are too few observations thall eqauls to 0 to 
#produce valuable result 
BANA_Comp_Data.cleaned = BANA_Comp_Data[thall != '0',]
#check 
unique(BANA_Comp_Data.cleaned$thall) #thall== 0 is removed 

#output
unique(output)

#Specify training data and testing data
train = sample(1:nrow(BANA_Comp_Data.cleaned),nrow(BANA_Comp_Data.cleaned)/2)

#input variable and output variable
x = model.matrix(output ~ ., data = BANA_Comp_Data.cleaned)[,-1]
y = BANA_Comp_Data.cleaned$output

#Generalized linear model
glm.fit.1 = glm(output ~ ., data = BANA_Comp_Data.cleaned[train,] ,
                family = binomial)
glm.fit.1
summary(glm.fit.1)


#predict probabilities 
glm.probs = predict(glm.fit.1, type="response", newdata = 
                      BANA_Comp_Data.cleaned[-train,] )


#replace the number with '0' or '1'
#0 means low chance of heart attack; while 1 means high chance of heart attack
#create a vector with all down first 
glm.pred = rep("0", dim(BANA_Comp_Data.cleaned)[1])

#find and replace value >0.5 with 1
glm.pred[glm.probs > 0.5] = "1"

#check the result by comparing the first 10 rows
glm.pred[1:10]
glm.probs[1:10]

#create Confusion  matrix to check how accurate of the model
cm = table(glm.pred, BANA_Comp_Data.cleaned$output)
cm

#calculate vectors of correct prediction (vcp) and store it 
vcp = (cm[1] + cm[4])/dim(BANA_Comp_Data)[1]
vcp

#MSE for null model 
null.pred = predict(glm.fit.1, newx = x[-train,], type = "response")
null_mse = mean((null.pred - y[-train])^2)


#Lasso 

#specify grid which the the value of lambda, the bigger the range the bigger 
#the penalty of more variables
grid = 10^seq(16, -2, length = 100)

#apply lasso 
lasso.fit = glmnet(x[train,], y[train], alpha = 1,family = "binomial", 
                   lambda = grid)
plot(lasso.fit)
##Depending on the choice of tuning parameter, some coefficients will be 
##exactly 0

#compute test error rate and compare with NULL model 

# Convert factor to numeric vector
y <- as.numeric(as.character(y)) 
cv.out <- cv.glmnet(x[train,], y[train], alpha = 1)

#visualization of showing TSE with different lambda
plot(cv.out)

#find best lambda with least TSE 
bestlam = cv.out$lambda.min
lasso.pred = predict(lasso.fit, s = bestlam, newx = x[-train,], 
                     type = "response")

#MSE for lasso 
lasso_mse = mean((lasso.pred - y[-train])^2)

#compare with null model
lasso_mse
null_mse
##the mse for lasso has less mse comparing with null model

#compute lasso coerfficients 
out = glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef = predict(out, type = "coefficients", s = bestlam)[1:20,]

#check lasso coefficient
lasso.coef

#check lasso coefficient which equal to zero
lasso.coef[lasso.coef != 0]


#visualization of significant factors

#show 4 visualizations at once 
par(mfrow = c(2,3))

#slp vs output
plot(BANA_Comp_Data.cleaned$slp[-train], lasso.pred, xlab = 'slp', 
     ylab = 'chance of heart attack')
title('relationship of slp and output')


#oldpeak vs output
plot(as.factor(BANA_Comp_Data.cleaned$oldpeak[-train]), lasso.pred, 
     xlab = 'oldpeak', ylab = 'chance of heart attack')
title('relationship of oldpeak and output')


#exng vs output
plot(BANA_Comp_Data.cleaned$exng[-train], lasso.pred, xlab = 'exng', 
     ylab = 'chance of heart attack')
title('relationship of exng and output')

#thallachh vs output
plot(BANA_Comp_Data.cleaned$thalachh[-train], lasso.pred, xlab = 'thallachh', 
     ylab = 'chance of heart attack')
title('relationship of thallachh and output')

#caa vs output
plot(BANA_Comp_Data.cleaned$caa[-train], lasso.pred, xlab = 'caa',
     ylab = 'chance of heart attack')
title('relationship of caa and output')

#thall vs output
plot(BANA_Comp_Data.cleaned$thall[-train], lasso.pred, xlab = 'thall',
     ylab = 'chance of heart attack')
title('relationship of thall and output')

#main title 
title('significant factors', outer = TRUE)


#allocate patients to 4 different levels based on the chance of 
#getting heart attack

#create a vector to store dangerous level of each patient
danger_lv =  c(rep('danger', dim(BANA_Comp_Data.cleaned)[1]))


# Remove missing values
glm.probs <- glm.probs[!is.na(glm.probs)]

# Initialize danger_lv vector
danger_lv <- rep(NA, length(glm.probs))

# Assign danger levels based on probabilities
for (i in 1:length(glm.probs)){
  if(glm.probs[i] > summary(glm.probs)[5]){
    danger_lv[i] = 'high danger'
  } else if(glm.probs[i] <= summary(glm.probs)[5] && glm.probs[i] > summary(glm.probs)[3]){ 
    danger_lv[i] = 'considerable danger'
  } else if(glm.probs[i] <= summary(glm.probs)[3] && glm.probs[i] > summary(glm.probs)[2]){ 
    danger_lv[i] = 'moderate danger'
  } else {
    danger_lv[i] = 'no or minor danger'
  }
}







```
